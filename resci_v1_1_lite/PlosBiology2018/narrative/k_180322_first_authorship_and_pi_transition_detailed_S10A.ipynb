{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from access_economic_data import nih\n",
    "from access_literature_data import medline, wos\n",
    "from access_science_shared import standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./../src/')\n",
    "import nar170604f_occurences as nar\n",
    "\n",
    "import ana170508f_human_citations as ana\n",
    "\n",
    "import resci_tools as ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resci_inout as inout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ealiest_year = 1980\n",
    "\n",
    "# years_for_citation = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_id = 9606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = False\n",
    "\n",
    "get_citations = True\n",
    "years_for_citation = 3     #  <----------    # ony applies if the above would be True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxon-independent datsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of taxon-indendent datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full MedLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For all research articles on gene-linked Medline \n",
    "# retreive pubmed_id and wos_id, and the amount of\n",
    "# authors\n",
    "df_m_any_taxon = medline.select_medline_wos_records(\n",
    "    columns_sql = '''\n",
    "            medline.pubmed_id,\n",
    "            ut2pmid.ut AS wos_id,\n",
    "            medline.amount_of_authors AS authors''',\n",
    "    taxon_id = 'all',\n",
    "    kind='research',\n",
    "    unambiguous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WoS of last authors to Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For any person that occurs in gene-linked WoS\n",
    "# retrieve wos, dais, and publication year of any\n",
    "# publication where the dais is a last author (note:\n",
    "# no further constraint, e.g.: on number of authors)\n",
    "p = inout.get_internal_path('wos_dais/all_queried_wos_with_dais.csv.gz')\n",
    "wos_dais_of_medline_pis = pd.read_csv(p, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene-linked WoS - DAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For any person that occurs in gene-linked WoS\n",
    "# retreive wos, dais, and authorship position\n",
    "wos_dais_gene_linked = wos.dais('gene-linked')\n",
    "wos_dais_gene_linked = wos_dais_gene_linked.sort_values([\n",
    "    'wos_id',\n",
    "    'position']).reset_index(drop=True).rename(\n",
    "        columns={'position':'authorship_position'})\n",
    "\n",
    "f = wos_dais_gene_linked['authorship_position'] == 1\n",
    "wos_dais_gene_linked.loc[f, 'authorship'] = 'first'\n",
    "\n",
    "f = wos_dais_gene_linked['authorship_position'] == 2\n",
    "wos_dais_gene_linked.loc[f, 'authorship'] = 'second'\n",
    "wos_dais_gene_linked = wos_dais_gene_linked.reset_index(drop=True)\n",
    "\n",
    "v = wos_dais_gene_linked['wos_id'].values\n",
    "is_last = np.concatenate((v[1:] != v[:-1], [True]))\n",
    "wos_dais_gene_linked.loc[is_last, 'authorship'] = 'senior'\n",
    "                \n",
    "wos_dais_gene_linked['authorship'] = wos_dais_gene_linked['authorship'].fillna('middle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WoS DAIS for Medline Research articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict WoS DAIS to research articles within MedLine\n",
    "# (or other medline datasets filtered as above to consider\n",
    "# to be main medline corpus of interest)\n",
    "wos_dais_gene_linked_resarch = wos_dais_gene_linked[\n",
    "    wos_dais_gene_linked['wos_id'].isin(\n",
    "        df_m_any_taxon['wos_id'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative taxon-independent datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For all of gene-linked wos, test if medline and WoS authorship\n",
    "# numbers align\n",
    "wos_dais_gene_linked = wos_dais_gene_linked.sort_values(\n",
    "    ['wos_id', 'authorship_position']).reset_index(drop=True)\n",
    "v = wos_dais_gene_linked['wos_id'].values\n",
    "f = np.concatenate((v[1:] != v[:-1], [True]))\n",
    "a = pd.merge(\n",
    "    wos_dais_gene_linked.loc[f, ['wos_id', 'authorship_position']],\n",
    "    df_m_any_taxon)\n",
    "a = a[a['authorship_position'] == a['authors']]\n",
    "wos_medline_matching_amount_of_authors = a[\n",
    "    ['wos_id', 'pubmed_id', 'authors']\n",
    "].rename(columns={'authors':'authors_equal_in_dais_and_medline'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define amount of publications as PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining PIs might be tricky since different disciplines\n",
    "# have somewhat different traditions and since WoS does \n",
    "# not allow distinguish between publication types; here: define papers\n",
    "# which have at least a certain amount of authos, and count\n",
    "# the number of such publications for every authors\n",
    "\n",
    "minimal_team_size_to_count_as_pi = 2\n",
    "\n",
    "papers_as_pi = wos_dais_of_medline_pis[\n",
    "    wos_dais_of_medline_pis['authorship_position']>=minimal_team_size_to_count_as_pi\n",
    "    ]['dais_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxon-dependent datasats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of taxon-dependent datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxons-specific gene2pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import genes, and pubmed for a given taxon. Note that\n",
    "# this is done on a per-taxon level as some lesser\n",
    "# model organisms do not support official nomeclature\n",
    "# (and thus might return less confident genes)\n",
    "ref_genes = standardizer.reference_genes(taxon_id, 'rpo')\n",
    "gene2pubmed = medline.gene2pubmed(\n",
    "    taxon_id= taxon_id,\n",
    "    paper_kind='research',\n",
    "    ref_genes=ref_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxon specific extended WoS profile (indluding amount of genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_sql='''\n",
    "            medline.pubmed_id,\n",
    "            medline.pubdate_year,\n",
    "            medline.amount_of_authors AS authors,\n",
    "            ut2pmid.ut AS wos_id'''\n",
    "kind ='research'\n",
    "unambiguous = True\n",
    "if get_citations:\n",
    "    years_range = 'all'\n",
    "else:\n",
    "    years_range = None\n",
    "\n",
    "df_m = medline.select_medline_wos_records(\n",
    "    columns_sql,\n",
    "    years_range=years_range,\n",
    "    taxon_id = taxon_id,\n",
    "    kind=kind,\n",
    "    unambiguous=unambiguous)\n",
    "\n",
    "df_m = df_m[df_m['pubmed_id'].isin(gene2pubmed['pubmed_id'])]\n",
    "\n",
    "\n",
    "columns_to_use = ['pubmed_id', 'wos_id', 'pubdate_year', 'authors']\n",
    "if get_citations:\n",
    "    df_m = ana.add_citations(df_m, years_to_include=years_for_citation)\n",
    "    columns_to_use = columns_to_use + ['citations']\n",
    "    \n",
    "df_m = df_m.loc[:,columns_to_use].drop_duplicates()\n",
    "\n",
    "if get_citations:\n",
    "    df_m = ana.add_yearly_citation_rank(df_m)\n",
    "\n",
    "df_m = df_m[df_m['authors']>0]   #                      < ---- have to check with other citation analysis\n",
    "\n",
    "    \n",
    "genes_per_paper = gene2pubmed['pubmed_id'].value_counts().to_frame('genes')\n",
    "df_m_specified_taxon = pd.merge(df_m, genes_per_paper, left_on='pubmed_id', right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxon specific cumulative annual fame of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = np.arange(1980, 2016)\n",
    "fame_of_interest = 'attention'\n",
    "\n",
    "df_h = medline.select_medline_records(\n",
    "    columns_sql='''\n",
    "        medline.pubmed_id,\n",
    "        medline.pubdate_year''',\n",
    "    taxon_id=taxon_id,\n",
    "    kind='research',\n",
    ")\n",
    "\n",
    "gene2pubmed_and_year = pd.merge(gene2pubmed, df_h[['pubmed_id', 'pubdate_year']])\n",
    "agg = []\n",
    "for y in span: \n",
    "    pa = nar.count_papers_and_attention(\n",
    "        ref_genes,\n",
    "        gene2pubmed_and_year[gene2pubmed_and_year['pubdate_year']<=y])\n",
    "\n",
    "    pa = pa[fame_of_interest]\n",
    "    pa.name = y\n",
    "    agg.append(pa)\n",
    "\n",
    "historic_fame = pd.concat(agg, axis=1)\n",
    "historic_rank = historic_fame.rank(ascending=False) / historic_fame.shape[0]\n",
    "\n",
    "df_ph = pd.merge(\n",
    "    df_h[['pubmed_id', 'pubdate_year']],\n",
    "    gene2pubmed[['gene_ncbi', 'pubmed_id']])\n",
    "\n",
    "agg = []\n",
    "for y in span:\n",
    "    yy = y  + 1\n",
    "    ser = historic_rank[y]\n",
    "    df = ser.to_frame('rank').reset_index(drop=False)\n",
    "    df.loc[:, 'year_and_one'] = yy\n",
    "    agg.append(df)\n",
    "df_ranks_for_future = pd.concat(agg)\n",
    "\n",
    "m = pd.merge(\n",
    "    df_ph,\n",
    "    df_ranks_for_future,\n",
    "    left_on=['gene_ncbi', 'pubdate_year'],\n",
    "    right_on=['gene_ncbi', 'year_and_one'])\n",
    "\n",
    "median_rank_of_genes_within_paper = m[['pubmed_id', 'rank']].groupby(\n",
    "    'pubmed_id').agg(np.median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative taxon-dependent datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earliest occurences of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.merge(\n",
    "    df_m_specified_taxon[['pubmed_id', 'pubdate_year', 'genes']],\n",
    "    gene2pubmed[['gene_ncbi', 'pubmed_id']])\n",
    "\n",
    "is_single_gene_paper = d['genes'] == 1\n",
    "\n",
    "genes_earliest_years = pd.merge(\n",
    "    d.loc[\n",
    "        :,\n",
    "        ['gene_ncbi', 'pubdate_year']].groupby(\n",
    "            'gene_ncbi').agg(min).reset_index().rename(\n",
    "                columns={'pubdate_year':'first_year'}),\n",
    "    d.loc[\n",
    "        is_single_gene_paper,\n",
    "        ['gene_ncbi', 'pubdate_year']].groupby(\n",
    "            'gene_ncbi').agg(min).reset_index().rename(\n",
    "                columns={'pubdate_year':'first_solo_year'}),\n",
    "    left_on = 'gene_ncbi',\n",
    "    right_on = 'gene_ncbi',\n",
    "    how = 'outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized author statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect information about individual authors. Note\n",
    "# that this section might be expanded subsequently\n",
    "minimal_team_size_to_count_as_non_solo = 2\n",
    "\n",
    "first_year_as_non_solo_last = wos_dais_of_medline_pis[wos_dais_of_medline_pis[\n",
    "    'authorship_position'] >= minimal_team_size_to_count_as_pi\n",
    "][['pubdate_year', 'dais_id']].groupby('dais_id').agg(min)\n",
    "\n",
    "b = pd.merge(\n",
    "    first_year_as_non_solo_last,\n",
    "    papers_as_pi.to_frame('papers_as_pi'),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how = 'inner').reset_index().rename(\n",
    "        columns={\n",
    "            'index':'dais_id',\n",
    "            'pubdate_year':'first_year_as_pi'})\n",
    "\n",
    "author_stats = pd.merge(\n",
    "    b,\n",
    "    wos_dais_gene_linked_resarch[['dais_id']].drop_duplicates(),\n",
    "    how='outer')\n",
    "\n",
    "author_stats['papers_as_pi'] = author_stats['papers_as_pi'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlg = pd.merge(\n",
    "    df_m_specified_taxon[['pubmed_id', 'pubdate_year']],\n",
    "    gene2pubmed[['gene_ncbi', 'pubmed_id']])\n",
    "\n",
    "papers_with_first_year = pd.merge(\n",
    "    mlg,\n",
    "    genes_earliest_years[['gene_ncbi', 'first_year']],\n",
    "    left_on=['gene_ncbi', 'pubdate_year'],\n",
    "    right_on=['gene_ncbi', 'first_year'], \n",
    "    how='inner')['pubmed_id'].unique()\n",
    "\n",
    "papers_with_first_solo_year = pd.merge(\n",
    "    mlg,\n",
    "    genes_earliest_years[['gene_ncbi', 'first_solo_year']],\n",
    "    left_on=['gene_ncbi', 'pubdate_year'],\n",
    "    right_on=['gene_ncbi', 'first_solo_year'], \n",
    "    how='inner')['pubmed_id'].unique()\n",
    "\n",
    "paper_stats = df_m_specified_taxon.copy()\n",
    "\n",
    "paper_stats.loc[:, 'premiere'] = paper_stats['pubmed_id'].isin(papers_with_first_year)\n",
    "paper_stats.loc[:, 'premiere_solo'] = paper_stats['pubmed_id'].isin(papers_with_first_solo_year)\n",
    "\n",
    "\n",
    "f = paper_stats['genes'] == 1\n",
    "paper_stats.loc[f, 'gene_group'] = '1'\n",
    "\n",
    "f = (paper_stats['genes'] > 1) & (paper_stats['genes'] <= 10)\n",
    "paper_stats.loc[f, 'gene_group'] = '2-10'\n",
    "\n",
    "f = (paper_stats['genes'] > 10)\n",
    "paper_stats.loc[f, 'gene_group'] = '11+'\n",
    "\n",
    "f = (paper_stats['gene_group'] == '1') & (paper_stats['premiere_solo'])\n",
    "paper_stats.loc[f, 'detailed_gene_group'] = '1_premiere'\n",
    "\n",
    "f = (paper_stats['gene_group'] == '1') & ~(paper_stats['premiere_solo'])\n",
    "paper_stats.loc[f, 'detailed_gene_group'] = '1_no_premiere'\n",
    "\n",
    "f = (paper_stats['gene_group'] == '2-10')\n",
    "paper_stats.loc[f, 'detailed_gene_group'] = '2-10'\n",
    "\n",
    "f = (paper_stats['gene_group'] == '11+')\n",
    "paper_stats.loc[f, 'detailed_gene_group'] = '11+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stats = pd.merge(\n",
    "    paper_stats,\n",
    "    wos_dais_gene_linked_resarch[\n",
    "    wos_dais_gene_linked_resarch['authorship'] == 'first'\n",
    "        ][['wos_id', 'dais_id']].rename(columns={'dais_id': 'dais_first_author'}),\n",
    "    left_on='wos_id',\n",
    "    right_on='wos_id',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_stats['pubmed_id'] = paper_stats['pubmed_id'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranks by gene\n",
    "paper_stats = pd.merge(\n",
    "    paper_stats,\n",
    "    median_rank_of_genes_within_paper.reset_index().rename(columns={'rank':'conventionality_rank'}),\n",
    "    how='left')\n",
    "        \n",
    "num_bins = 5\n",
    "paper_stats['conventionality_bin'] = (\n",
    "    paper_stats['conventionality_rank'] * num_bins).apply(lambda x: np.floor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank by papers within same year\n",
    "paper_stats['conventionality_rank_rank'] = paper_stats[['pubdate_year', 'conventionality_rank']].groupby('pubdate_year').rank(pct=True)\n",
    "\n",
    "num_bins = 5\n",
    "paper_stats['conventionality_rank_rank_bin'] = (\n",
    "    paper_stats['conventionality_rank_rank'] * num_bins).apply(lambda x: np.floor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_minimal_amount_of_papers_as_pi = 3\n",
    "\n",
    "pool = pd.merge(\n",
    "    paper_stats,\n",
    "    author_stats,\n",
    "    left_on='dais_first_author',\n",
    "    right_on='dais_id',\n",
    "    how='inner')\n",
    "\n",
    "pool.loc[:, 'will_be_pi'] = (\n",
    "    pool['first_year_as_pi'] >= pool['pubdate_year']) & (\n",
    "    pool['papers_as_pi'] >= required_minimal_amount_of_papers_as_pi)\n",
    "\n",
    "f = (pool['first_year_as_pi']<pool['pubdate_year']) == True   # < --------- important\n",
    "pool = pool.loc[~f, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do first authors of different types of papers have different prospects to advance to PI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pool[['dais_first_author', 'pubdate_year','detailed_gene_group', 'will_be_pi']].drop_duplicates()\n",
    "mini = mini[mini['pubdate_year']>=1980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeper = mini.groupby(['detailed_gene_group', 'pubdate_year']).size().reset_index()\n",
    "keeper = keeper[keeper[0]>=50].drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(\n",
    "    x='pubdate_year',\n",
    "    y='will_be_pi',\n",
    "    hue='detailed_gene_group',\n",
    "    data=pd.merge(mini, keeper),\n",
    "    hue_order=['11+', '2-10', '1_no_premiere', '1_premiere'],\n",
    "    n_boot=10000)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_visible(False)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "    label.set_visible(True)\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "if save_images:\n",
    "    ret.export_image('170806_first_authorship_and_pi_transition/likelihood_to_transition_to_pi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do first types of papers have different amount of citations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_citations: \n",
    "    mini = pool[['pubmed_id', 'pubdate_year', 'citations', 'yearly_citation_rank', 'detailed_gene_group', 'will_be_pi']].drop_duplicates()\n",
    "    mini = mini[mini['pubdate_year']>=1980]\n",
    "    \n",
    "    ax = sns.pointplot(\n",
    "        x='pubdate_year',\n",
    "        y='yearly_citation_rank',\n",
    "        hue='detailed_gene_group',\n",
    "        data=mini,\n",
    "        estimator=np.median,\n",
    "        hue_order=['11+', '2-10', '1_no_premiere', '1_premiere'],\n",
    "        n_boot=10000)\n",
    "\n",
    "    for label in ax.xaxis.get_ticklabels():\n",
    "        label.set_visible(False)\n",
    "\n",
    "    for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "        label.set_visible(True)\n",
    "\n",
    "    ax.set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_citations: \n",
    "    \n",
    "    keeper = mini.groupby(['detailed_gene_group', 'pubdate_year']).size().reset_index()\n",
    "    keeper = keeper[keeper[0]>=50].drop(0, axis=1)\n",
    "\n",
    "    ax = sns.pointplot(\n",
    "        x='pubdate_year',\n",
    "        y='citations',\n",
    "        hue='detailed_gene_group',\n",
    "        data=pd.merge(mini, keeper),\n",
    "        estimator=np.median,\n",
    "        hue_order=['11+', '2-10', '1_no_premiere', '1_premiere'],\n",
    "        n_boot=10000)\n",
    "\n",
    "    ax.set_ylim(0,50)\n",
    "\n",
    "    for label in ax.xaxis.get_ticklabels():\n",
    "        label.set_visible(False)\n",
    "\n",
    "    for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "        label.set_visible(True)\n",
    "\n",
    "    if save_images:\n",
    "        ret.export_image('170806_first_authorship_and_pi_transition/median_citations.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are papers of future PIs differenentially cited?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_citations: \n",
    "    \n",
    "    mini = pool[['pubdate_year', 'citations', 'yearly_citation_rank', 'will_be_pi']]\n",
    "    mini = mini[mini['pubdate_year']>=1980]\n",
    "    \n",
    "    ax = sns.pointplot(\n",
    "        x='pubdate_year',\n",
    "        y='yearly_citation_rank',\n",
    "        hue='will_be_pi',\n",
    "        data=mini,\n",
    "        estimator=np.median,\n",
    "        n_boot=10000)\n",
    "\n",
    "\n",
    "    for label in ax.xaxis.get_ticklabels():\n",
    "        label.set_visible(False)\n",
    "\n",
    "    for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "        label.set_visible(True)\n",
    "\n",
    "    ax.set_ylim(0,1)\n",
    "\n",
    "\n",
    "    if save_images:\n",
    "        ret.export_image('170806_first_authorship_and_pi_transition/citations_of_future_pis.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do papers with more unconventional genes have lower chance of PI (as implied in Hoffmann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pool.loc[:, [\n",
    "    'dais_first_author',\n",
    "    'pubdate_year',\n",
    "    'conventionality_bin',\n",
    "    'will_be_pi']].drop_duplicates()\n",
    "mini = mini[mini['pubdate_year']>=1980]\n",
    "\n",
    "keeper = mini.groupby(['conventionality_bin', 'pubdate_year']).size().reset_index()\n",
    "keeper = keeper[keeper[0]>=50].drop(0, axis=1)\n",
    "\n",
    "\n",
    "ax = sns.pointplot(\n",
    "    x='pubdate_year',\n",
    "    y='will_be_pi',\n",
    "    hue='conventionality_bin',\n",
    "    data=pd.merge(mini, keeper),\n",
    "    hue_order=[4, 3, 2, 1, 0],\n",
    "    n_boot=10000)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_visible(False)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "    label.set_visible(True)\n",
    "    \n",
    "    \n",
    "if save_images:\n",
    "    ret.export_image('170806_first_authorship_and_pi_transition/gene_conventionality_bins.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pool.loc[:, [\n",
    "    'dais_first_author',\n",
    "    'pubdate_year',\n",
    "    'conventionality_bin',\n",
    "    'will_be_pi']].drop_duplicates()\n",
    "mini = mini[mini['pubdate_year']>=1980]\n",
    "\n",
    "keeper = mini.groupby(['conventionality_bin', 'pubdate_year']).size().reset_index()\n",
    "keeper = keeper[keeper[0]>=50].drop(0, axis=1)\n",
    "\n",
    "\n",
    "ax = sns.pointplot(\n",
    "    x='pubdate_year',\n",
    "    y='will_be_pi',\n",
    "    hue='conventionality_bin',\n",
    "    data=pd.merge(mini[mini['conventionality_bin'].isin([0, 4])], keeper),\n",
    "    hue_order=[4, 0],\n",
    "    n_boot=10000)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_visible(False)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "    label.set_visible(True)\n",
    "    \n",
    "\n",
    "if save_images:\n",
    "    ret.export_image('170806_first_authorship_and_pi_transition/gene_extreme_conventionality_bins.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pool.loc[:, [\n",
    "    'dais_first_author',\n",
    "    'pubdate_year',\n",
    "    'conventionality_bin',\n",
    "    'will_be_pi']].drop_duplicates()\n",
    "mini = mini[mini['pubdate_year']>=2000]\n",
    "\n",
    "keeper = mini.groupby(['conventionality_bin', 'pubdate_year']).size().reset_index()\n",
    "keeper = keeper[keeper[0]>=50].drop(0, axis=1)\n",
    "\n",
    "\n",
    "ax = sns.pointplot(\n",
    "    x='pubdate_year',\n",
    "    y='will_be_pi',\n",
    "    hue='conventionality_bin',\n",
    "    data=pd.merge(mini[mini['conventionality_bin'].isin([0, 4])], keeper),\n",
    "    hue_order=[4, 0],\n",
    "    n_boot=10000)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_visible(False)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "    label.set_visible(True)\n",
    "    \n",
    "\n",
    "if save_images:\n",
    "    ret.export_image('170806_first_authorship_and_pi_transition/gene_extreme_conventionality_bins_since_2000.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pool.loc[:, [\n",
    "    'dais_first_author',\n",
    "    'pubdate_year',\n",
    "    'conventionality_bin',\n",
    "    'will_be_pi']].drop_duplicates()\n",
    "mini = mini[mini['pubdate_year']>=2000]\n",
    "\n",
    "keeper = mini.groupby(['conventionality_bin', 'pubdate_year']).size().reset_index()\n",
    "keeper = keeper[keeper[0]>=50].drop(0, axis=1)\n",
    "\n",
    "\n",
    "ax = sns.pointplot(\n",
    "    x='pubdate_year',\n",
    "    y='will_be_pi',\n",
    "    hue='conventionality_bin',\n",
    "    data=pd.merge(mini[mini['conventionality_bin'].isin([0, 2, 4])], keeper),\n",
    "    hue_order=[4, 2, 0],\n",
    "    dodge=True,\n",
    "    n_boot=10000)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels():\n",
    "    label.set_visible(False)\n",
    "\n",
    "for label in ax.xaxis.get_ticklabels()[0::5]:\n",
    "    label.set_visible(True)\n",
    "    \n",
    "\n",
    "if save_images:\n",
    "    ret.export_image('180322_first_authorship_and_pi_transition_detailed/gene_extreme_conventionality_bins_with_center_since_2000.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
